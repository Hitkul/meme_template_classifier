{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jellyfish import metaphone as mt\n",
    "from jellyfish import soundex as su\n",
    "from jellyfish import nysiis as ni\n",
    "from jellyfish import match_rating_codex as mrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>image_name</th>\n",
       "      <th>link</th>\n",
       "      <th>org_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y U No</td>\n",
       "      <td>\\n                            The Y U No meme ...</td>\n",
       "      <td>0</td>\n",
       "      <td>/Y-U-No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willy Wonka</td>\n",
       "      <td>\\n                            \\nWilly Wonka Me...</td>\n",
       "      <td>1</td>\n",
       "      <td>/Willy-Wonka</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Most Interesting Man In The World</td>\n",
       "      <td>\\n                            Dos Equis Beer w...</td>\n",
       "      <td>2</td>\n",
       "      <td>/The-Most-Interesting-Man-In-The-World</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futurama Fry</td>\n",
       "      <td>\\n                            Futurama Fry sho...</td>\n",
       "      <td>3</td>\n",
       "      <td>/Futurama-Fry</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Success Kid</td>\n",
       "      <td>\\n                            If you come acro...</td>\n",
       "      <td>4</td>\n",
       "      <td>/Success-Kid</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title  \\\n",
       "0                                 Y U No   \n",
       "1                            Willy Wonka   \n",
       "2  The Most Interesting Man In The World   \n",
       "3                           Futurama Fry   \n",
       "4                            Success Kid   \n",
       "\n",
       "                                         description  image_name  \\\n",
       "0  \\n                            The Y U No meme ...           0   \n",
       "1  \\n                            \\nWilly Wonka Me...           1   \n",
       "2  \\n                            Dos Equis Beer w...           2   \n",
       "3  \\n                            Futurama Fry sho...           3   \n",
       "4  \\n                            If you come acro...           4   \n",
       "\n",
       "                                     link  org_label  \n",
       "0                                 /Y-U-No          0  \n",
       "1                            /Willy-Wonka          1  \n",
       "2  /The-Most-Interesting-Man-In-The-World          2  \n",
       "3                           /Futurama-Fry          3  \n",
       "4                            /Success-Kid          4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#....................................loading original datset.....................................................................\n",
    "title_description=pd.read_csv('/home/shivangi/Downloads/PHD/Phd_Courses/Monsoon_Sem_2018/IMC/Project/meme_template_classifier/title_description.csv')\n",
    "title_description['org_label'] = title_description.index\n",
    "title_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "# title_description['title'].str.lower()\n",
    "# title_description['title'].str.replace(\"-\",\" \")\n",
    "for i in range(10):\n",
    "    title_description['link']=title_description['link'].str.replace(\" \",\"\",1)\n",
    "    title_description['link']=title_description['link'].str.replace(\"/\",\"\",1)\n",
    "    title_description['link']=title_description['link'].str.lower()\n",
    "    title_description['link']=title_description['link'].str.replace(\"-\",\"\",1)\n",
    "    title_description['link']=title_description['link'].str.replace(\"-\",\"\",1)\n",
    "    title_description['link']=title_description['link'].str.replace(\"-\",\"\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>original</th>\n",
       "      <th>dl1</th>\n",
       "      <th>dl2</th>\n",
       "      <th>dl3</th>\n",
       "      <th>dl4</th>\n",
       "      <th>dl5</th>\n",
       "      <th>dl6</th>\n",
       "      <th>dl7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90s-problems</td>\n",
       "      <td>sad-face-guy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1889-10-guy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aaaand-its-gone</td>\n",
       "      <td>aand-its-gone</td>\n",
       "      <td>and-its-gone</td>\n",
       "      <td>south-park-aand-its-gone</td>\n",
       "      <td>youre-gonna-have-a-bad-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>advice-borat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  S.No         original            dl1           dl2  \\\n",
       "1    1     90s-problems   sad-face-guy           NaN   \n",
       "2    2      1889-10-guy            NaN           NaN   \n",
       "3    3  aaaand-its-gone  aand-its-gone  and-its-gone   \n",
       "4    4       aboriginal            NaN           NaN   \n",
       "5    5     advice-borat            NaN           NaN   \n",
       "\n",
       "                        dl3                          dl4  dl5  dl6  dl7  \n",
       "1                       NaN                          NaN  NaN  NaN  NaN  \n",
       "2                       NaN                          NaN  NaN  NaN  NaN  \n",
       "3  south-park-aand-its-gone  youre-gonna-have-a-bad-time  NaN  NaN  NaN  \n",
       "4                       NaN                          NaN  NaN  NaN  NaN  \n",
       "5                       NaN                          NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ........................classes..............................................................................\n",
    "class_meme=pd.read_csv('/home/shivangi/Downloads/PHD/Phd_Courses/Monsoon_Sem_2018/IMC/Project/meme_template_classifier/class_meme.csv' ) \n",
    "class_meme.columns = ['S.No','original','dl1','dl2','dl3','dl4','dl5','dl6','dl7']\n",
    "x_cls=class_meme.drop(class_meme.index[[0]])\n",
    "x_cls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some pre-processing on link coloum:\n",
    "for i in range(10):\n",
    "    for coloumn in list(x_cls):\n",
    "        x_cls[coloumn]=x_cls[coloumn].str.replace(\" \",\"\",1)\n",
    "        x_cls[coloumn]=x_cls[coloumn].str.replace(\"/\",\"\",1)\n",
    "        x_cls[coloumn]=x_cls[coloumn].str.lower()\n",
    "        x_cls[coloumn]=x_cls[coloumn].str.replace(\"-\",\"\",1)\n",
    "        x_cls[coloumn]=x_cls[coloumn].str.replace(\"-\",\"\",1)\n",
    "        x_cls[coloumn]=x_cls[coloumn].str.replace(\"-\",\"\",1)\n",
    "\n",
    "# x_cls\n",
    "# trim(preg_replace('/-+/', '-', $str), '-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing words by numbers\n",
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['o1'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls, pd_temp, left_on = 'original', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('original', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d1'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl1', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl1', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d2'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl2', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl2', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d3'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl3', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl3', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d4'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl4', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl4', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d5'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl5', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl5', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d6'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl6', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl6', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_temp = pd.DataFrame()\n",
    "pd_temp['link'] = title_description['link']\n",
    "pd_temp['d7'] = title_description['image_name']\n",
    "x_cls_v2 = pd.merge(x_cls_v2, pd_temp, left_on = 'dl7', right_on = 'link', how = 'left')\n",
    "x_cls_v2 = x_cls_v2.drop('dl7', 1)\n",
    "x_cls_v2 = x_cls_v2.drop('link', 1)\n",
    "# x_cls_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # finding duplicates on manually annotated file.................\n",
    "# names=list(x_cls)\n",
    "# names.pop(0)\n",
    "# # title_description['new link'].str.lower()\n",
    "# x_cls['original'].str.lower()\n",
    "# for i in range(len(title_description)):\n",
    "#     for j in range(1,len(x_cls)):\n",
    "#         for k in names:\n",
    "#             title_description['link'].str.replace(\" \",\"\",1)\n",
    "#             title_description['link'].str.replace(\"/\",\"\",1)title_description['link'].str.lower()\n",
    "# title_description['link']=title_description['link'].str.replace(\"-\",\"\",1)\n",
    "# title_description['link']=title_description['link'].str.replace(\"-\",\"\",1)\n",
    "# title_description['link']=title_description['link'].str.replace(\"-\",\"\",1)\n",
    "#             if(title_description['new_link'].loc[i]==x_cls[k].loc[j]):\n",
    "#                 x_cls[k].loc[j]=title_description['image_name'].loc[i]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ........method-1:fingerprinting of the titles....................\n",
    "meta=[]\n",
    "soundex=[]\n",
    "nysiis=[]\n",
    "match_codex=[]\n",
    "for i in range(len(title_description)):\n",
    "    meta.append(mt(title_description['title'].loc[i]))\n",
    "#     soundex.append(su(title_description['title'].loc[i]))\n",
    "    nysiis.append(ni(title_description['title'].loc[i]))\n",
    "    match_codex.append(mrc(title_description['title'].loc[i]))\n",
    "    \n",
    "\n",
    "title_description['meta']=meta\n",
    "title_description['nyiis']=nysiis\n",
    "title_description['matchCodex']=match_codex\n",
    "# title_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame([[k,v.values]\n",
    "for k,v in title_description.groupby('meta').groups.items()], columns=['meta','meta_index'])\n",
    "\n",
    "\n",
    "df2=pd.DataFrame([[k,v.values]\n",
    "for k,v in title_description.groupby('nyiis').groups.items()], columns=['nyiis','nyiis_index'])\n",
    "\n",
    "df3=pd.DataFrame([[k,v.values]\n",
    "for k,v in title_description.groupby('matchCodex').groups.items()], columns=['match_codex','match_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ........method-2: sift on images....................\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ...........classification..............................\n",
    "\n",
    "# STEP-1 : finding unique template numbers for which captions are to be extracted\n",
    "\n",
    "# ....converting rows into a list bcz elements in each row are same so anyone of the embeddings will be considered among them.\n",
    "# dup- is a list of list where each list shares same template\n",
    "# e.g- [372,386] - both the templates are same, take any one of the sentences out of two\n",
    "\n",
    "dup=[]           \n",
    "duplicates=x_cls_v2.values.tolist()\n",
    "for lis in duplicates:\n",
    "    lis.pop(0)\n",
    "    duplicate_list=[ele for ele in lis if str(ele) != 'nan']\n",
    "    dup.append(duplicate_list)\n",
    "\n",
    "    \n",
    "# since elements within same are considered equivalent so any of them could be chosen for further classification\n",
    "# Assumption: chosing first element of the every list or chosing the 'o1' coloumn from x_cls_v2 dataframe.\n",
    "template=x_cls_v2['o1'].tolist()\n",
    "unique_template=set(template)\n",
    "len(unique_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/shivangi/Downloads/PHD/Phd_Courses/Monsoon Sem 2018/IMC/Project/data/captions'\n",
    "for x in unique_classes:\n",
    "    path='/home/shivangi/Downloads/PHD/Phd_Courses/Monsoon Sem 2018/IMC/Project/data/captions/0.txt'\n",
    "    x_file = open(path, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='/home/shivangi/Downloads/PHD/Phd_Courses/Monsoon Sem 2018/IMC/Project/data/captions/0.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(path, \"5_1.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (meme)",
   "language": "python",
   "name": "meme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
